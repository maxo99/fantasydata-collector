{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from stagehand import StagehandConfig, Stagehand\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "config = StagehandConfig.model_validate(\n",
    "    dict(\n",
    "        env=\"LOCAL\",\n",
    "        model_api_key=os.getenv(\"OPENAI_API_KEY\", \"\"),\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5fe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:07:43</span> <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span> - Launching new local browser context<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:07:43\u001b[0m \u001b[36mINFO\u001b[0m - Launching new local browser context\u001b[1;37m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:07:43</span> <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span> - Local browser context launched successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:07:43\u001b[0m \u001b[36mINFO\u001b[0m - Local browser context launched successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:07:49</span> <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">observe</span> - Starting observation for task: <span style=\"color: #008000; text-decoration-color: #008000\">'Click the drop down below '</span>#select-advanced-*<span style=\"color: #008000; text-decoration-color: #008000\">' </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with `View` as the displayed text'</span>'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:07:49\u001b[0m \u001b[36mINFO\u001b[0m \u001b[1;34mobserve\u001b[0m - Starting observation for task: \u001b[32m'Click the drop down below '\u001b[0m#select-advanced-*\u001b[32m' \u001b[0m\n",
       "\u001b[32mwith `View` as the displayed text'\u001b[0m'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:07:53</span> <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span> - Getting accessibility tree data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:07:53\u001b[0m \u001b[36mINFO\u001b[0m - Getting accessibility tree data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:08:11</span> <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span> - Calling LLM\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:08:11\u001b[0m \u001b[36mINFO\u001b[0m - Calling LLM\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:08:15</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR</span> <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">llm</span> - Error calling litellm.completion: litellm.RateLimitError: RateLimitError: \n",
       "OpenAIException - Request too large for gpt-4o in organization org-TKnVEqrDrQaJY2K1L5AWzsqe on tokens per min \n",
       "<span style=\"font-weight: bold\">(</span>TPM<span style=\"font-weight: bold\">)</span>: Limit <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30000</span>, Requested <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">137626</span>. The input or output tokens must be reduced in order to run successfully. \n",
       "Visit <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://platform.openai.com/account/rate-limits</span> to learn more.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:08:15\u001b[0m \u001b[1;31mERROR\u001b[0m \u001b[1;34mllm\u001b[0m - Error calling litellm.completion: litellm.RateLimitError: RateLimitError: \n",
       "OpenAIException - Request too large for gpt-4o in organization org-TKnVEqrDrQaJY2K1L5AWzsqe on tokens per min \n",
       "\u001b[1m(\u001b[0mTPM\u001b[1m)\u001b[0m: Limit \u001b[1;36m30000\u001b[0m, Requested \u001b[1;36m137626\u001b[0m. The input or output tokens must be reduced in order to run successfully. \n",
       "Visit \u001b[4;94mhttps://platform.openai.com/account/rate-limits\u001b[0m to learn more.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:08:15</span> <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR</span> - Error in observe inference: litellm.RateLimitError: RateLimitError: OpenAIException - \n",
       "Request too large for gpt-4o in organization org-TKnVEqrDrQaJY2K1L5AWzsqe on tokens per min <span style=\"font-weight: bold\">(</span>TPM<span style=\"font-weight: bold\">)</span>: Limit <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30000</span>, \n",
       "Requested <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">137626</span>. The input or output tokens must be reduced in order to run successfully. Visit \n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://platform.openai.com/account/rate-limits</span> to learn more.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:08:15\u001b[0m \u001b[1;31mERROR\u001b[0m - Error in observe inference: litellm.RateLimitError: RateLimitError: OpenAIException - \n",
       "Request too large for gpt-4o in organization org-TKnVEqrDrQaJY2K1L5AWzsqe on tokens per min \u001b[1m(\u001b[0mTPM\u001b[1m)\u001b[0m: Limit \u001b[1;36m30000\u001b[0m, \n",
       "Requested \u001b[1;36m137626\u001b[0m. The input or output tokens must be reduced in order to run successfully. Visit \n",
       "\u001b[4;94mhttps://platform.openai.com/account/rate-limits\u001b[0m to learn more.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">2025</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">08</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">-</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">12</span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\"> </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf; font-weight: bold\">18:08:15</span> <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span> - Getting xpath for element\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2;37m2025\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m08\u001b[0m\u001b[2;37m-\u001b[0m\u001b[1;2;37m12\u001b[0m\u001b[2;37m \u001b[0m\u001b[1;2;37m18:08:15\u001b[0m \u001b[36mINFO\u001b[0m - Getting xpath for element\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e=TypeError('Object of type ObserveResult is not JSON serializable')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stagehand = Stagehand(config)\n",
    "try:\n",
    "    await stagehand.init()\n",
    "    page = stagehand.page\n",
    "    if not page:\n",
    "        raise ValueError(\"no page\")\n",
    "    \n",
    "\n",
    "    await page.goto(\"https://www.fantasypros.com/nfl/rankings/ppr-cheatsheets.php\")\n",
    "\n",
    "    action_preview = await page.observe(\n",
    "        \"Click the drop down below '#select-advanced-*' with `View` as the displayed text'\"\n",
    "    )\n",
    "\n",
    "    print(f\"{[a.model_dump for a in action_preview]}\")\n",
    "    await page.act(action_preview[0])\n",
    "except Exception as e:\n",
    "    print(f\"{e=}\")\n",
    "finally:\n",
    "    await stagehand.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasypros-rankings-pull",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
